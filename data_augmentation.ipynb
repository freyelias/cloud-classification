{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2a096b-a305-4c25-95f7-44200eb0f9c9",
   "metadata": {},
   "source": [
    "# Training Images Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9e2a5-f588-4821-bad9-e0787d3ed707",
   "metadata": {},
   "source": [
    "This script performs data augmentation techniques specifically chosen for webcam images showing different cloud conditions. Those are used to train different CNN models to predict cloud types. The \"offline\" data augmentation technique of this script will increase the diversity of the image dataset by adding multiple (random) variations to the pictures and saving them as copies. This procedure will therefore also increase the dataset size itself. Image augmentation should only be done on training, not validation images!\n",
    "\n",
    "Author: Elias Frey, RSGB/Unibe \\\n",
    "Date: 02.10.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4554d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-frederick",
   "metadata": {},
   "source": [
    "### Define Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "danish-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "lab_img_path = 'data/cropped_images'\n",
    "aug_img_path = 'data/aug_test'\n",
    "\n",
    "# Chose if original picture should be included in the final augmentation set\n",
    "apply_copy_org = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf81bea-0113-42c4-ab43-d7bf35e4b48c",
   "metadata": {},
   "source": [
    "### Directory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a9fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(aug_img_path):\n",
    "        os.makedirs(aug_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97f868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_copy_org:\n",
    "    for filename in os.listdir(lab_img_path):\n",
    "        org_path = os.path.join(lab_img_path, filename)\n",
    "        if os.path.isfile(org_path):\n",
    "            new_fn = f\"{filename.split('.')[0]}_org.jpg\"\n",
    "            aug_path = os.path.join(aug_img_path, new_fn)\n",
    "            # Original image will be copied to the augmentation directory\n",
    "            shutil.copy(org_path, aug_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962be6bf",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b468542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auglist(rnd_int):\n",
    "    \"\"\"\n",
    "    Augmentation function that combines all selected augmentations and ensure high amount of diversity in the final augmented dataset\n",
    "    \"\"\"\n",
    "    # List containing all augmentations\n",
    "    augmentations_list = [\n",
    "        \n",
    "        # 0. Random brightness contrast cropped\n",
    "        A.Compose([A.OneOf([A.Sequential([A.RandomBrightnessContrast(brightness_limit=(-0.15, 0.15), contrast_limit=(-0.15, 0.15), p=1),\n",
    "                                         A.Rotate(limit=(-20, -45), p=1),\n",
    "                                         ]),\n",
    "\n",
    "                            A.Sequential([A.RandomBrightnessContrast(brightness_limit=(-0.15, 0.15), contrast_limit=(-0.15, 0.15), p=1),\n",
    "                                          A.RandomSizedCrop([250, 250], image_size, image_size, p=1),\n",
    "                                          A.Rotate(limit=(15,35), p=1)\n",
    "                                         ]),\n",
    "                           ], p=1,\n",
    "                          ),\n",
    "\n",
    "                   A.SomeOf([A.HorizontalFlip(p=1), A.VerticalFlip(p=1)],\n",
    "                            rnd_int,\n",
    "                            p=1),\n",
    "                  ]),\n",
    "\n",
    "        # 1. Gaussian noise (org/cropped)\n",
    "        A.Compose([A.OneOf([A.Sequential([A.GaussNoise(var_limit=[8,10], per_channel=False, p=1),\n",
    "                                          A.Rotate(limit=(-20, -45), p=1),\n",
    "                                         ]),\n",
    "\n",
    "                            A.Sequential([A.GaussNoise(var_limit=[8,10], per_channel=False, p=1),\n",
    "                                          A.RandomSizedCrop([250, 250], image_size, image_size, p=1),\n",
    "                                          A.Rotate(limit=(15,35), p=1)\n",
    "                                         ]),\n",
    "                           ], p=1,\n",
    "                          ),\n",
    "\n",
    "                   A.SomeOf([A.HorizontalFlip(p=1), A.VerticalFlip(p=1)],\n",
    "                            rnd_int,\n",
    "                            p=1),\n",
    "                  ]),\n",
    "\n",
    "        # 2. Color jitter (org/cropped)\n",
    "        A.Compose([A.OneOf([A.Sequential([A.ColorJitter(brightness=0, contrast=0, saturation=0.1, hue=(0.05, 0.05), p=1),\n",
    "                                          A.Rotate(limit=(20, 45), p=1),\n",
    "                                         ]),\n",
    "\n",
    "                            A.Sequential([A.ColorJitter(brightness=0, contrast=0, saturation=0.1, hue=(-0.05, 0.05), p=1),\n",
    "                                          A.RandomSizedCrop([250, 250], image_size, image_size, p=1),\n",
    "                                          A.Rotate(limit=(-15, -35), p=1),\n",
    "                                         ]),\n",
    "                           ], p=1,\n",
    "                          ),\n",
    "                   \n",
    "                   A.SomeOf([A.HorizontalFlip(p=1), A.VerticalFlip(p=1)],\n",
    "                            rnd_int,\n",
    "                            p=1),\n",
    "                  ]),\n",
    "    ]\n",
    "    return augmentations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7f211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation\n",
    "for img_filename in os.listdir(lab_img_path):\n",
    "        img_path = os.path.join(lab_img_path, img_filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        augmentations_list = get_auglist(np.random.randint(low=1, high=3))\n",
    "        for idx, sel_augmentation in enumerate(augmentations_list):\n",
    "            sel_augmentation[len(sel_augmentation)-1].n = np.random.randint(low=1, high=3)\n",
    "            #print(f'{sel_augmentation[len(sel_augmentation)-1].n} -- AFTER')\n",
    "            augmented_image = sel_augmentation(image=img)['image']\n",
    "            augmented_filename = f\"{img_filename.split('.')[0]}_aug{idx}.jpg\"\n",
    "            augmented_path = os.path.join(aug_img_path, augmented_filename)\n",
    "            cv2.imwrite(augmented_path, augmented_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
